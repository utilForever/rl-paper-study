## 4th Study Paper List

Date | Paper | Presenter | Links
:---: | :---: | :---: | :---:
3/29 | Dueling Network Architectures for Deep Reinforcement Learning, Wang et al, 2015. | Jiyun Kim | [[paper]](https://arxiv.org/abs/1511.06581) [[review]](./210329%20-%20Dueling%20Network%20Architectures%20for%20Deep%20Reinforcement%20Learning%2C%20Wang%20et%20al%2C%202015.pdf)
3/29 | Sim-to-Real Leaning of All Common Bipedal Gaits via Periodic Reward Composition, J. Siekmann et al, 2020. | Hansol Kang | [[paper]](https://arxiv.org/abs/2011.01387) [[review]](./210329%20-%20Sim-to-Real%20Leaning%20of%20All%20Common%20Bipedal%20Gaits%20via%20Periodic%20Reward%20Composition%2C%20J.%20Siekmann%20et%20al%2C%202020.pdf)
4/5 | Asynchronous Methods for Deep Reinforcement Learning, Mnih et al, 2016. | Jiwon Chong | [[paper]](https://arxiv.org/abs/1602.01783) [[review]](./210405%20-%20Asynchronous%20Methods%20for%20Deep%20Reinforcement%20Learning%2C%20Mnih%20et%20al%2C%202016.pdf)
4/12 | Adversarially Guided Actor-Critic, Y. Flet-Berliac et al, 2021. | Chris Ohk | [[paper]](https://arxiv.org/abs/2102.04376) [[review]](./210412%20-%20Adversarially%20Guided%20Actor-Critic%2C%20Y.%20Flet-Berliac%20et%20al%2C%202021.pdf)
4/12 | Hindsight Experience Replay, M. Andrychowicz et al, 2017. | Donggu Kang | [[paper]](https://arxiv.org/abs/1707.01495) [[review]](./210412%20-%20Hindsight%20Experience%20Replay%2C%20M.%20Andrychowicz%20et%20al%2C%202017.pdf)
4/19 | Addressing Function Approximation Error in Actor-Critic Methods, S. Fujimoto et al, 2018. | Junhyun Park | [[paper]](https://arxiv.org/abs/1802.09477) [[review]](./210419%20-%20Addressing%20Function%20Approximation%20Error%20in%20Actor-Critic%20Methods%2C%20S.%20Fujimoto%20et%20al%2C%202018.pdf)
4/19 | Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments, R. Lowe et al, 2017. | Seungeon Baek | [[paper]](https://arxiv.org/abs/1706.02275) [[review]](./210419%20-%20Multi-Agent%20Actor-Critic%20for%20Mixed%20Cooperative-Competitive%20Environments%2C%20R.%20Lowe%20et%20al%2C%202017.pdf)
4/26 | Generating Text with Deep Reinforcement Learning, H. Guo et al, 2015. | Wonho Lee | [[paper]](https://arxiv.org/abs/1510.09202) [[review]](./210426%20-%20Generating%20Text%20with%20Deep%20Reinforcement%20Learning%2C%20H.%20Guo%20et%20al%2C%202015.pdf)
5/3 | Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor, T. Haarnoja et al, 2018. | Soohan Kang | [[paper]](https://arxiv.org/abs/1801.01290) [[review]](./210503%20-%20Soft%20Actor-Critic%20Off-Policy%20Maximum%20Entropy%20Deep%20Reinforcement%20Learning%20with%20a%20Stochastic%20Actor%2C%20T.%20Haarnoja%20et%20al%2C%202018.pdf)
5/10 | Randomized Ensembled Double Q-Learning: Learning Fast Without a Model, X. Chen et al, 2021. | Jungyeon Lee | [[paper]](https://arxiv.org/abs/2101.05982) [[review]](./210510%20-%20Randomized%20Ensembled%20Double%20Q-Learning%20Learning%20Fast%20Without%20a%20Model%2C%20X.%20Chen%20et%20al%2C%202021.pdf)
5/17 | Efficient Hyperparameters Optimization Through Model-based Reinforcement Learning and Meta-Learning, J. Wu et al, 2020. | Wonwoo Choi | [[paper]](https://ieeexplore.ieee.org/abstract/document/9408061) [[review]](./210517%20-%20Efficient%20Hyperparameters%20Optimization%20Through%20Model-based%20Reinforcement%20Learning%20and%20Meta-Learning%2C%20J.%20Wu%20et%20al%2C%202020.pdf)
5/17 | Continuous Control with Deep Reinforcement Learning, TP. Lillicrap et al, 2015. | Bongseok Kim | [[paper]](https://arxiv.org/abs/1509.02971) [[review]](./210517%20-%20Continuous%20Control%20with%20Deep%20Reinforcement%20Learning%2C%20TP.%20Lillicrap%20et%20al%2C%202015.pdf)
5/24 | Demand-Aware Career Path Recommendations: A Reinforcement Learning Approach, M. Kokkodis et al, 2020. | Minkyu Shin | [[paper]](https://pubsonline.informs.org/doi/pdf/10.1287/mnsc.2020.3727) [review]
5/24 | Deep Reinforcement Learning for Dialogue Generation, J. Li et al, 2016. | Daejin Jo | [[paper]](https://arxiv.org/abs/1606.01541) [review]
5/31 | Distributional Reinforcement Learning with Quantile Regression, W. Dabney et al, 2017. | Jiae Lee | [[paper]](https://arxiv.org/abs/1710.10044) [review]
5/31 | Human-Level Control through Deep Reinforcement Learning, Mnih et al. 2015. | Kangbeen Ko | [[paper]](https://www.nature.com/articles/nature14236?wm=book_wap_0005) [review]

### Study Member

* [Chris Ohk](http://www.github.com/utilForever)
* [Jiyun Kim](http://www.github.com/Helia-17)
* [Hansol Kang](http://www.github.com/OnesoulKang)
* Jiwon Chong
* [Donggu Kang](http://www.github.com/HERIUN)
* [Junhyun Park](http://www.github.com/jundev1l2l)
* [Seungeon Baek](http://www.github.com/SeungeonBaek)
* [Wonho Lee](http://www.github.com/lee-wonho)
* Soohan Kang
* Jiae Lee
* [Jungyeon Lee](http://www.github.com/curieuxjy)
* [Kangbeen Ko](http://www.github.com/KevinTheRainmaker)
* [Wonwoo Choi](http://www.github.com/deepwonwoo)
* Bongseok Kim
* Minkyu Shin
* [Daejin Jo](http://www.github.com/twidddj)